# PPPM-TDBEM

## Requirements

- Ubuntu 20.04
- CUDA version >= 11.5
- CMake version >= 3.23
- Catch2 (for unit test)
- docker (for fix mesh using pymesh)
- libglfw3-dev libglew-dev (for visualization)
- libpng (for storing picture)

## Experiments

Experiments are all under `experiments` directory.

### Demo

`experiments/demo` is the directory that we generate demo. After building the executable `demo`, you can run it by:

```bash
./demo CONFIG_PATH
```

where the config is a json-like file:

```json
{
    inputDir: "...",
    outputDir: "...",
    res: 40,
    gridLengthFactor: 2,
    maxTime: 10.0,
    checkCoordX: 0.875,
    checkCoordY: 0.875,
    checkCoordZ: 0.875,
    sceneInfo: [
    	{
    	    name: "phone",
    	    type: "Audio"
    	},
    	{
    	    name: "cup",
    	    type: "Manual"
    	}
    ]
}
```

The parser is written by ourselves and very simple, and you may not change the layout. The `inputDir` is the root directory where the scene is stored, and the `outputDir` will store the final result. Each object should be stored in a sub-directory with name in `sceneInfo`.

There are three types of the objects that we consider:

+ Manual: No motion and no sound at all. The only thing that should be in `ManualObject/` is its wavefront obj file that is named as `mesh.obj`.
+ Audio: Have motion and optional pre-recorded sound. Besides `mesh.obj`, these files are also needed: 
  + `motion.txt`: Compulsory. Each line of `motion.txt` is essentially `time_point translation_x translation_y translation_z rotation_x rotation_y rotation_z rotation_w`.
  + `accs.txt`: Optional. This file stores the surface accelerations of the object and is generated by the pre-recorded sound in the `.wav` format. The conversion can be done by `experiments/WavConvert/convert.ipynb`. If this file is not provided, we will regard the object as silent.
  + `selected_vertices.txt`: Optional. Sometimes sound outgoes from only partial surfaces, and this file conveys the vertices that are selected to enable surfaces' accelerations. If this file is not provided, all surface triangles will be attached with the acceleration.
+ Modal: Have motion and modal informations that can be used for sound synthesis. For these object, tetrahedron mesh is required.
  + `vertices.txt & tets.txt`: Describe the vertices and the tetrahedrons that compose the object. The former is coordinates of vertices and the latter is IDs of four vertices of a tetrahedron.
  + `motion.txt`: Same as Audio, but the time step should be smaller to make modal analysis more accurate.
  + `eigenvalues.txt & eigenvectors.txt`: Describe the eigen values and eigen vectors of the object.
  + `contacts.txt`: ???

For example, in the phone-cup scene in our demo, the phone is Audio type and the cup is Manual type.

Other parameters in the configuration mean:

+ `res`: The resolution of the grid in our method.
+ `gridLengthFactor`: The factor that is multiplied to the bounding box to satisfy the requirements of the grid in our method. Usually `2.0` is enough.
+ `maxTime`: Simulation time, expected to be `<= min(motionTime, soundTime)`. 
+ `checkCoordX/Y/Z`: The relative position of the listener. "Relative" means the coordinate when the simulation cube is normalized to the canonical one.

These parameters may be tuned to fit different scenes.

After running `./demo CONFIG_PATH`, `result.txt` and `mesh_seqeuence/*` will be written to the `outputDir`. For the former, `experiments/demo/audio_convert.py` can be used to convert the result back to the `.wav` audio; for the latter, `blender --python ROOT_DIR/python_scripts/blender_loader.py` can be used to show raw animation.



